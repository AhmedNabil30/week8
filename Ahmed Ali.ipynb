{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to generate a random user-item matrix with some missing values (NaNs)\n",
        "def generate_random_matrix(n_users, n_items, sparsity=0.2):\n",
        "    matrix = np.random.rand(n_users, n_items)\n",
        "    mask = np.random.rand(n_users, n_items) > sparsity  # Create a sparsity mask\n",
        "    matrix[mask] = np.nan  # Set random entries to NaN (missing values)\n",
        "    return matrix\n",
        "\n",
        "# Matrix Factorization using Stochastic Gradient Descent (SGD)\n",
        "def matrix_factorization_sgd(R, num_features, learning_rate=0.01, reg_param=0.02, num_iterations=1000):\n",
        "    \"\"\"\n",
        "    Perform matrix factorization using Stochastic Gradient Descent (SGD).\n",
        "    :param R: User-item matrix with missing values (NaNs)\n",
        "    :param num_features: Number of latent features for matrix factorization\n",
        "    :param learning_rate: Learning rate for SGD\n",
        "    :param reg_param: Regularization parameter to avoid overfitting\n",
        "    :param num_iterations: Number of SGD iterations\n",
        "    :return: P (user feature matrix), Q (item feature matrix)\n",
        "    \"\"\"\n",
        "    # Initialize user and item matrices with random values\n",
        "    num_users, num_items = R.shape\n",
        "    P = np.random.rand(num_users, num_features)  # User latent feature matrix\n",
        "    Q = np.random.rand(num_items, num_features)  # Item latent feature matrix\n",
        "\n",
        "    # Iterate through the training process\n",
        "    for iteration in range(num_iterations):\n",
        "        for i in range(num_users):\n",
        "            for j in range(num_items):\n",
        "                if not np.isnan(R[i, j]):  # Only update for known ratings\n",
        "                    error_ij = R[i, j] - np.dot(P[i, :], Q[j, :].T)  # Calculate error\n",
        "                    # Update the latent factors using SGD with regularization\n",
        "                    P[i, :] += learning_rate * (2 * error_ij * Q[j, :] - reg_param * P[i, :])\n",
        "                    Q[j, :] += learning_rate * (2 * error_ij * P[i, :] - reg_param * Q[j, :])\n",
        "\n",
        "        # Optionally, print the error every few iterations\n",
        "        if iteration % 100 == 0:\n",
        "            error = 0\n",
        "            for i in range(num_users):\n",
        "                for j in range(num_items):\n",
        "                    if not np.isnan(R[i, j]):\n",
        "                        error += (R[i, j] - np.dot(P[i, :], Q[j, :].T)) ** 2\n",
        "            print(f\"Iteration {iteration} - error: {error}\")\n",
        "\n",
        "    return P, Q\n",
        "\n",
        "# Reconstruct the matrix by multiplying the user and item matrices\n",
        "def reconstruct_matrix(P, Q):\n",
        "    return np.dot(P, Q.T)\n",
        "\n",
        "# Predict missing values in the user-item matrix\n",
        "def predict_missing_values(R, P, Q):\n",
        "    predicted_matrix = reconstruct_matrix(P, Q)\n",
        "    return predicted_matrix\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    n_users = 5  # Number of users\n",
        "    n_items = 6  # Number of items\n",
        "    num_features = 3  # Number of latent features for matrix factorization\n",
        "\n",
        "    # Step 1: Generate a random matrix (user-item interaction matrix)\n",
        "    R = generate_random_matrix(n_users, n_items)\n",
        "    print(\"Original User-Item Matrix (with missing values):\")\n",
        "    print(np.round(R, 2))\n",
        "\n",
        "    # Step 2: Perform matrix factorization using SGD\n",
        "    P, Q = matrix_factorization_sgd(R, num_features, num_iterations=1000, learning_rate=0.01, reg_param=0.02)\n",
        "\n",
        "    # Step 3: Predict the missing values\n",
        "    predicted_matrix = predict_missing_values(R, P, Q)\n",
        "    print(\"\\nPredicted User-Item Matrix:\")\n",
        "    print(np.round(predicted_matrix, 2))\n",
        "\n",
        "    # Step 4: Reconstruct the original matrix (for comparison)\n",
        "    reconstructed_matrix = reconstruct_matrix(P, Q)\n",
        "    print(\"\\nReconstructed User-Item Matrix (after factorization):\")\n",
        "    print(np.round(reconstructed_matrix, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GF2EctX0PZd",
        "outputId": "86a3a98e-b793-416e-a3ee-75d3f8fd9468"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original User-Item Matrix (with missing values):\n",
            "[[ nan  nan  nan  nan  nan  nan]\n",
            " [ nan 0.67 0.82  nan  nan  nan]\n",
            " [ nan 0.91  nan  nan  nan  nan]\n",
            " [ nan  nan  nan  nan  nan  nan]\n",
            " [ nan  nan  nan  nan  nan 0.09]]\n",
            "Iteration 0 - error: 0.5429643290919917\n",
            "Iteration 100 - error: 0.006611896753902188\n",
            "Iteration 200 - error: 0.0004975809315759102\n",
            "Iteration 300 - error: 0.00027407089661859736\n",
            "Iteration 400 - error: 0.0002609918735961719\n",
            "Iteration 500 - error: 0.0002660502605675207\n",
            "Iteration 600 - error: 0.0002731907055966697\n",
            "Iteration 700 - error: 0.0002801888739114739\n",
            "Iteration 800 - error: 0.00028668454816026853\n",
            "Iteration 900 - error: 0.0002926243440567916\n",
            "\n",
            "Predicted User-Item Matrix:\n",
            "[[0.71 0.86 0.93 0.4  1.03 0.5 ]\n",
            " [0.61 0.66 0.81 0.21 0.93 0.37]\n",
            " [0.79 0.9  0.9  0.45 1.03 0.45]\n",
            " [1.01 0.98 0.56 0.71 0.82 0.17]\n",
            " [1.07 0.98 0.51 0.71 0.82 0.09]]\n",
            "\n",
            "Reconstructed User-Item Matrix (after factorization):\n",
            "[[0.71 0.86 0.93 0.4  1.03 0.5 ]\n",
            " [0.61 0.66 0.81 0.21 0.93 0.37]\n",
            " [0.79 0.9  0.9  0.45 1.03 0.45]\n",
            " [1.01 0.98 0.56 0.71 0.82 0.17]\n",
            " [1.07 0.98 0.51 0.71 0.82 0.09]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Function to generate a random user-item matrix with some missing values (NaNs)\n",
        "def generate_random_matrix(n_users, n_items, sparsity=0.2):\n",
        "    matrix = np.random.rand(n_users, n_items)\n",
        "    mask = np.random.rand(n_users, n_items) > sparsity  # Create a sparsity mask\n",
        "    matrix[mask] = np.nan  # Set random entries to NaN (missing values)\n",
        "    return matrix\n",
        "\n",
        "# Matrix Factorization using Stochastic Gradient Descent (SGD)\n",
        "def matrix_factorization_sgd(R, num_features, learning_rate=0.01, reg_param=0.02, num_iterations=1000):\n",
        "    \"\"\"\n",
        "    Perform matrix factorization using Stochastic Gradient Descent (SGD).\n",
        "    :param R: User-item matrix with missing values (NaNs)\n",
        "    :param num_features: Number of latent features for matrix factorization\n",
        "    :param learning_rate: Learning rate for SGD\n",
        "    :param reg_param: Regularization parameter to avoid overfitting\n",
        "    :param num_iterations: Number of SGD iterations\n",
        "    :return: P (user feature matrix), Q (item feature matrix)\n",
        "    \"\"\"\n",
        "    # Initialize user and item matrices with random values\n",
        "    num_users, num_items = R.shape\n",
        "    P = np.random.rand(num_users, num_features)  # User latent feature matrix\n",
        "    Q = np.random.rand(num_items, num_features)  # Item latent feature matrix\n",
        "\n",
        "    # Measure the start time of the matrix factorization process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate through the training process\n",
        "    for iteration in range(num_iterations):\n",
        "        for i in range(num_users):\n",
        "            for j in range(num_items):\n",
        "                if not np.isnan(R[i, j]):  # Only update for known ratings\n",
        "                    error_ij = R[i, j] - np.dot(P[i, :], Q[j, :].T)  # Calculate error\n",
        "                    # Update the latent factors using SGD with regularization\n",
        "                    P[i, :] += learning_rate * (2 * error_ij * Q[j, :] - reg_param * P[i, :])\n",
        "                    Q[j, :] += learning_rate * (2 * error_ij * P[i, :] - reg_param * Q[j, :])\n",
        "\n",
        "        # Optionally, print the error every few iterations\n",
        "        if iteration % 100 == 0:\n",
        "            error = 0\n",
        "            for i in range(num_users):\n",
        "                for j in range(num_items):\n",
        "                    if not np.isnan(R[i, j]):\n",
        "                        error += (R[i, j] - np.dot(P[i, :], Q[j, :].T)) ** 2\n",
        "            print(f\"Iteration {iteration} - error: {error}\")\n",
        "\n",
        "    # Measure the end time of the matrix factorization process\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time  # Time taken for matrix factorization\n",
        "\n",
        "    print(f\"\\nMatrix factorization took {elapsed_time:.4f} seconds for {num_iterations} iterations.\")\n",
        "\n",
        "    return P, Q, elapsed_time\n",
        "\n",
        "# Reconstruct the matrix by multiplying the user and item matrices\n",
        "def reconstruct_matrix(P, Q):\n",
        "    return np.dot(P, Q.T)\n",
        "\n",
        "# Predict missing values in the user-item matrix\n",
        "def predict_missing_values(R, P, Q):\n",
        "    predicted_matrix = reconstruct_matrix(P, Q)\n",
        "    return predicted_matrix\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    n_users = 5  # Number of users\n",
        "    n_items = 6  # Number of items\n",
        "    num_features = 3  # Number of latent features for matrix factorization\n",
        "    num_iterations = 1000  # Number of iterations for SGD\n",
        "\n",
        "    # Step 1: Generate a random matrix (user-item interaction matrix)\n",
        "    R = generate_random_matrix(n_users, n_items)\n",
        "    print(\"Original User-Item Matrix (with missing values):\")\n",
        "    print(np.round(R, 2))\n",
        "\n",
        "    # Step 2: Perform matrix factorization using SGD\n",
        "    P, Q, elapsed_time = matrix_factorization_sgd(R, num_features, num_iterations=num_iterations, learning_rate=0.01, reg_param=0.02)\n",
        "\n",
        "    # Step 3: Predict the missing values\n",
        "    predicted_matrix = predict_missing_values(R, P, Q)\n",
        "    print(\"\\nPredicted User-Item Matrix:\")\n",
        "    print(np.round(predicted_matrix, 2))\n",
        "\n",
        "    # Step 4: Reconstruct the original matrix (for comparison)\n",
        "    reconstructed_matrix = reconstruct_matrix(P, Q)\n",
        "    print(\"\\nReconstructed User-Item Matrix (after factorization):\")\n",
        "    print(np.round(reconstructed_matrix, 2))\n",
        "\n",
        "    # Time Complexity of the Matrix Factorization Process (Empirical)\n",
        "    total_operations = n_users * n_items * num_iterations\n",
        "    print(f\"\\nEmpirical Time Complexity: ~O({total_operations})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j16WaK9316w",
        "outputId": "949b3872-492c-4921-868e-9e662afd3475"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original User-Item Matrix (with missing values):\n",
            "[[ nan  nan  nan  nan  nan  nan]\n",
            " [ nan  nan  nan 0.39  nan  nan]\n",
            " [ nan  nan  nan  nan  nan  nan]\n",
            " [ nan  nan  nan  nan  nan 0.75]\n",
            " [ nan  nan  nan  nan  nan  nan]]\n",
            "Iteration 0 - error: 0.015019233857983698\n",
            "Iteration 100 - error: 0.00015572740580339505\n",
            "Iteration 200 - error: 0.00013769339709648412\n",
            "Iteration 300 - error: 0.00013580028172268077\n",
            "Iteration 400 - error: 0.00013828986607573548\n",
            "Iteration 500 - error: 0.0001414203820425016\n",
            "Iteration 600 - error: 0.00014455953039796703\n",
            "Iteration 700 - error: 0.00014761065448610965\n",
            "Iteration 800 - error: 0.00015055666709735906\n",
            "Iteration 900 - error: 0.0001533927918162002\n",
            "\n",
            "Matrix factorization took 0.1174 seconds for 1000 iterations.\n",
            "\n",
            "Predicted User-Item Matrix:\n",
            "[[1.11 0.8  0.73 0.39 1.27 1.17]\n",
            " [0.36 0.47 0.54 0.38 0.39 0.36]\n",
            " [0.65 0.54 0.53 0.34 0.73 0.67]\n",
            " [0.68 0.72 0.77 0.4  0.79 0.74]\n",
            " [0.86 1.07 1.2  0.69 0.99 0.93]]\n",
            "\n",
            "Reconstructed User-Item Matrix (after factorization):\n",
            "[[1.11 0.8  0.73 0.39 1.27 1.17]\n",
            " [0.36 0.47 0.54 0.38 0.39 0.36]\n",
            " [0.65 0.54 0.53 0.34 0.73 0.67]\n",
            " [0.68 0.72 0.77 0.4  0.79 0.74]\n",
            " [0.86 1.07 1.2  0.69 0.99 0.93]]\n",
            "\n",
            "Empirical Time Complexity: ~O(30000)\n"
          ]
        }
      ]
    }
  ]
}